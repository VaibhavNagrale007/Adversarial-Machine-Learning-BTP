{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaibhavNagrale007/Adversarial-Machine-Learning-BTP/blob/main/Sem%207/red_attack_xray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am sharing the implementation of the RED attack on the CNN model using the GTSRB dataset. You can download that dataset from the internet and replicate the results. Also, implement the same in medical images for CNN and a Vision Transformer of your choice."
      ],
      "metadata": {
        "id": "9O3mIgfsGIbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Augmentor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdkHrPzN4aMC",
        "outputId": "424384fb-7650-4d68-fe6b-9e2b7d8e7eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Augmentor\n",
            "  Downloading Augmentor-0.2.12-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (9.4.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (1.23.5)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Augmentor\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil, glob, os.path\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9mFs2E8rxejK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38d4aac-49d9-4a66-90b1-d9d24b65d803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imdir = '/content/drive/MyDrive/Dataset/xray_pneumonia/train/'\n",
        "test_imdir = '/content/drive/MyDrive/Dataset/xray_pneumonia/test/'\n",
        "val_imdir = '/content/drive/MyDrive/Dataset/xray_pneumonia/val/'\n",
        "\n",
        "r = Augmentor.Pipeline(val_imdir)\n",
        "r.flip_left_right(0.5)\n",
        "r.rotate(0.3, 10, 10)\n",
        "r.skew(0.4, 0.5)\n",
        "r.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
        "r.sample(500)\n",
        "\n",
        "p = Augmentor.Pipeline(train_imdir)\n",
        "p.flip_left_right(0.5)\n",
        "p.rotate(0.3, 10, 10)\n",
        "p.skew(0.4, 0.5)\n",
        "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
        "p.sample(500)"
      ],
      "metadata": {
        "id": "EHjNd_7cxU1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "c1e902e4-ad89-4b06-fbf5-53c0c1e47138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 16 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/Dataset/xray_pneumonia/val/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=L size=1776x1416 at 0x7AFC4C245570>: 100%|██████████| 500/500 [00:42<00:00, 11.73 Samples/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-38461d495d1d>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAugmentor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip_left_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_directory, output_directory, save_format)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msource_directory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             self._populate(source_directory=source_directory,\n\u001b[0m\u001b[1;32m     88\u001b[0m                            \u001b[0moutput_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                            \u001b[0mground_truth_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36m_populate\u001b[0;34m(self, source_directory, output_directory, ground_truth_directory, ground_truth_output_directory)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_output_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_output_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_populate_image_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36m_check_images\u001b[0;34m(self, abs_output_directory)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maugmentor_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmentor_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct_dimensions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct_formats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def img_labels(path):\n",
        "  images = []\n",
        "  img_cnt = 0\n",
        "  imdir = path + 'output/NORMAL'\n",
        "  filelist = glob.glob(os.path.join(imdir, '*.jpeg'))\n",
        "  if filelist == [] :\n",
        "    imdir = path + 'NORMAL'\n",
        "    filelist = glob.glob(os.path.join(imdir, '*.jpeg'))\n",
        "  filelist.sort()\n",
        "  for j, imagepath in enumerate(filelist):\n",
        "      img1 = cv2.imread(filelist[j])\n",
        "      img1 = cv2.resize(img1, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "      images.append(img1)\n",
        "      img_cnt = img_cnt + 1\n",
        "  imdir = path + 'output/PNEUMONIA'\n",
        "  filelist = glob.glob(os.path.join(imdir, '*.jpeg'))\n",
        "  if filelist == [] :\n",
        "    imdir = path + 'PNEUMONIA'\n",
        "    filelist = glob.glob(os.path.join(imdir, '*.jpeg'))\n",
        "  filelist.sort()\n",
        "  for j, imagepath in enumerate(filelist):\n",
        "      img1= cv2.imread(filelist[j])\n",
        "      img1 = cv2.resize(img1, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "      images.append(img1)\n",
        "\n",
        "  labels = 0\n",
        "  for i in range(1,len(images)):\n",
        "    if(i<img_cnt):\n",
        "      labels = np.vstack ((labels, 0) )\n",
        "    else:\n",
        "      labels = np.vstack ((labels, 1) )\n",
        "\n",
        "  print(\"Number of images: \", len(images))\n",
        "  print(\"Number of labels: \", len(labels))\n",
        "\n",
        "  images=np.stack(images,axis=0)\n",
        "  print(\"Images shape: \", images.shape)\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "# train\n",
        "train_images, train_labels = img_labels(train_imdir)\n",
        "\n",
        "# val\n",
        "val_images, val_labels = img_labels(val_imdir)\n",
        "\n",
        "# test\n",
        "test_images, test_labels = img_labels(test_imdir)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images, val_images = train_images / 255.0, test_images / 255.0, val_images / 255.0"
      ],
      "metadata": {
        "id": "qdUGZf434j5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase image dimension and correct the code\n",
        "# tp = test_images\n",
        "# print(\"previous: \",tp)\n",
        "# tp = tf.expand_dims(tp, axis=-1)\n",
        "# print(\"new\", tp)"
      ],
      "metadata": {
        "id": "BJciOnVQc5gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(44, 44, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='sigmoid'))\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(val_images, val_labels))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "brOc703n3_nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZZ41aHKWSN_"
      },
      "source": [
        "#import dill\n",
        "#dill.load_session('gtsrb.db')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l97Vk1F3cNio"
      },
      "source": [
        "!pip install Augmentor\n",
        "!unzip trainingbenign.zip\n",
        "!unzip trainingmalign.zip\n",
        "!unzip testbenign.zip\n",
        "!unzip testmalign.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzqTBfUTacOf"
      },
      "source": [
        "#importing useful libraries\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil, glob, os.path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import Augmentor\n",
        "# Passing the path of the image directory\n",
        "p = Augmentor.Pipeline(\"trainingbenign\")\n",
        "p.flip_left_right(0.5)\n",
        "#p.black_and_white(0.1)\n",
        "p.rotate(0.3, 10, 10)\n",
        "p.skew(0.4, 0.5)\n",
        "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
        "p.sample(500)\n",
        "\n",
        "q = Augmentor.Pipeline(\"trainingmalign\")\n",
        "q.flip_left_right(0.5)\n",
        "#p.black_and_white(0.1)\n",
        "q.rotate(0.3, 10, 10)\n",
        "q.skew(0.4, 0.5)\n",
        "q.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
        "q.sample(750)\n",
        "\n",
        "imdir = \"trainingbenign\"\n",
        "filelist = glob.glob(os.path.join(imdir, '*.bmp'))\n",
        "filelist.sort()\n",
        "images=[]\n",
        "for j, imagepath in enumerate(filelist):\n",
        "    img1 = cv2.imread(filelist[j])\n",
        "    img1 = cv2.resize(img1, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "    images.append(img1)\n",
        "imdir = \"trainingbenign/output\"\n",
        "filelist = glob.glob(os.path.join(imdir, '*.bmp'))\n",
        "filelist.sort()\n",
        "for j, imagepath in enumerate(filelist):\n",
        "    img1= cv2.imread(filelist[j])\n",
        "    img1 = cv2.resize(img1, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "    images.append(img1)\n",
        "print(len(images))\n",
        "\n",
        "imdir = \"trainingmalign\"\n",
        "filelist = glob.glob(os.path.join(imdir, '*.bmp'))\n",
        "filelist.sort()\n",
        "for j, imagepath in enumerate(filelist):\n",
        "    img1 = cv2.imread(filelist[j])\n",
        "    img1 = cv2.resize(img1, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "    images.append(img1)\n",
        "imdir = \"trainingmalign/output\"\n",
        "filelist = glob.glob(os.path.join(imdir, '*.bmp'))\n",
        "filelist.sort()\n",
        "for j, imagepath in enumerate(filelist):\n",
        "    img1= cv2.imread(filelist[j])\n",
        "    img1 = cv2.resize(img1, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "    images.append(img1)\n",
        "print(len(images))\n",
        "labels = 0\n",
        "for i in range(1,len(images)):\n",
        "  if(i<580):\n",
        "    labels = np.vstack ((labels, 0) )\n",
        "  else:\n",
        "    labels = np.vstack ((labels, 1) )\n",
        "\n",
        "images=np.stack(images,axis=0)\n",
        "print(images.shape)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, val_images = train_images / 255.0, val_images / 255.0\n",
        "\n",
        "imdir = \"testbenign\"\n",
        "filelist = glob.glob(os.path.join(imdir, '*.bmp'))\n",
        "filelist.sort()\n",
        "images=[]\n",
        "for j, imagepath in enumerate(filelist):\n",
        "    img1 = cv2.imread(filelist[j])\n",
        "    img1 = cv2.resize(img1, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "    images.append(img1)\n",
        "print(len(images))\n",
        "imdir = \"testmalign\"\n",
        "filelist = glob.glob(os.path.join(imdir, '*.bmp'))\n",
        "filelist.sort()\n",
        "for j, imagepath in enumerate(filelist):\n",
        "    img1 = cv2.imread(filelist[j])\n",
        "    img1 = cv2.resize(img1, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "    images.append(img1)\n",
        "print(len(images))\n",
        "labels=0\n",
        "for i in range(1,len(images)):\n",
        "  if(i<20):\n",
        "    labels = np.vstack ((labels, 0) )\n",
        "  else:\n",
        "    labels = np.vstack ((labels, 1) )\n",
        "images=np.stack(images,axis=0)\n",
        "print(images.shape)\n",
        "test_images, test_labels = images,labels\n",
        "test_images=test_images/255.0\n",
        "print(len(test_images))\n",
        "print(len(test_labels))\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(44, 44, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='sigmoid'))\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(val_images, val_labels))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltm6czMyWSON"
      },
      "source": [
        "def max_diff(img1,img2):\n",
        "    img = img1 - img2\n",
        "    return np.amax(img)\n",
        "\n",
        "def pred(image):\n",
        "    data = []\n",
        "    data.append(image)\n",
        "    X_test = np.array(data)\n",
        "    X_test = X_test.astype('float32')/255\n",
        "    # pred = model.predict_classes(X_test)\n",
        "    pred = np.argmax(model.predict(X_test),axis=1)\n",
        "    return pred[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZl8sCBdWSOW"
      },
      "source": [
        "def boundary_estimation(source, target, dmin):\n",
        "    Ii = ((source + target)/2.0)\n",
        "    k = pred(Ii)\n",
        "    delta = max_diff(source, Ii)\n",
        "    Ia2 = source\n",
        "    Ib2 = target\n",
        "    p = Ib2\n",
        "    while (delta > dmin):\n",
        "        if (pred(Ia2) != k):\n",
        "            Ib2 = Ii\n",
        "        else:\n",
        "            Ia2 = Ii\n",
        "        Ii = ((Ia2+Ib2)/2.0)\n",
        "        k = pred(Ii)\n",
        "        delta = max_diff(Ia2,Ii)\n",
        "    return Ii"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7Ldb5VYWSOe"
      },
      "source": [
        "def go_out(source,iout,alpha):\n",
        "    i_diff = iout - source\n",
        "    pred_source = pred(source)\n",
        "    inew = iout\n",
        "    while (pred(inew)==pred_source):\n",
        "        inew = inew + alpha*(i_diff)\n",
        "\n",
        "    return inew"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIJfrd-8eIYY"
      },
      "source": [
        "pip install -U setuptools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAsxZpAzdFNn"
      },
      "source": [
        "!pip install preprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "def preprocess(img_path):\n",
        "    # img = tf.expand_dims(img, axis=-1)\n",
        "    # img = cv2.resize(img, (44, 44), interpolation=cv2.INTER_LINEAR)\n",
        "    # return img\n",
        "    img = image.load_img(img_path, target_size=(44, 44))\n",
        "    img_array = image.img_to_array(img)\n",
        "    # img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "S3_wdKxoVT4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQFYFqVgWSOl"
      },
      "source": [
        "from PIL import Image\n",
        "source_image_path = test_imdir + 'NORMAL/IM-0001-0001.jpeg';\n",
        "target_image_path = test_imdir + 'PNEUMONIA/person100_bacteria_475.jpeg';\n",
        "# img = (np.asarray(Image.open(source_image_path)))\n",
        "# img1 = preprocess(img)\n",
        "# source_image = np.array(img1)\n",
        "# img = (np.asarray(Image.open(target_image_path)))\n",
        "# img2 = preprocess(img)\n",
        "# target_image = np.array(img2)\n",
        "source_image = preprocess(source_image_path)\n",
        "target_image = preprocess(target_image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(source_image.shape)"
      ],
      "metadata": {
        "id": "JpkvUiONbL7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TjJX7aSWSOu"
      },
      "source": [
        "i = boundary_estimation(source_image,target_image,1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRV-ZOGkWSO6"
      },
      "source": [
        "print (pred(i))\n",
        "print (pred(source_image))\n",
        "print (pred(target_image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GroDS2X5WSPD"
      },
      "source": [
        "ii = go_out(source_image,i,0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXiJv8w4WSPL",
        "outputId": "42486fbb-dbb4-49d7-90a7-b56b67905620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "pred(ii)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-96cbb2a7c98a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ii' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sLChdyOWSPS"
      },
      "source": [
        "Image.fromarray(i.astype('uint8')).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OysSNArVWSPZ"
      },
      "source": [
        "Image.fromarray(ii.astype('uint8')).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke-qGbkHWSPg"
      },
      "source": [
        "def array_diff(d1):\n",
        "    sumd1 = 0.0\n",
        "    for i in range(0,3):\n",
        "        for j in range(0,30):\n",
        "            for k in range(0,30):\n",
        "                d1[j][k][i] = d1[j][k][i]*d1[j][k][i]\n",
        "                sumd1 = sumd1 + d1[j][k][i]\n",
        "    return (sumd1)\n",
        "\n",
        "def gradient_estimation(source, target, adversarial, n, theta):\n",
        "    Ia = source\n",
        "    Ib = target\n",
        "    Ii = adversarial\n",
        "    Io = np.zeros((2700))\n",
        "    X = np.random.randint(0,2700, size=n)\n",
        "    for i in X:\n",
        "        Io[i] = 255\n",
        "    Io = Io.reshape((30,30,3))\n",
        "#     print(Io*theta)\n",
        "    Ii2 = Ii + theta*Io\n",
        "    Ii2_new = boundary_estimation(Ia, Ii2, 1.0)\n",
        "    Ii2_new = go_out(source,Ii2_new,0.01)\n",
        "    diff2 = Ii2_new - Ia\n",
        "    diff1 = Ii - Ia\n",
        "    d2 = array_diff(diff2)\n",
        "    d1 = array_diff(diff1)\n",
        "    if (d2 > d1):\n",
        "        return (-1, Ii2_new)\n",
        "    elif (d1 > d2):\n",
        "        return (1, Ii2_new)\n",
        "    else:\n",
        "        return (0,Ii2_new)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FayzjQUWSPp"
      },
      "source": [
        "def efficient_update(source, target, adversarial, I2, g, j):\n",
        "    Ia = source\n",
        "    Ib = target\n",
        "    Ii = adversarial\n",
        "    Ii2 = I2\n",
        "    delta = g*(Ii2 - Ii)\n",
        "    l = j\n",
        "    Inew = Ii + l*delta\n",
        "\n",
        "    diff1 = Inew - Ia\n",
        "    diff2 = Ii - Ia\n",
        "    d1 = array_diff(diff1)\n",
        "    d2 = array_diff(diff2)\n",
        "    ii = 0\n",
        "    it = 0\n",
        "    while(d1 > d2):\n",
        "        l = (l/2.0)\n",
        "        Inew = Ii + l*delta\n",
        "        if(pred(Inew)==pred(source)):\n",
        "            Inew = go_out(source,Inew,0.01)\n",
        "        it = it + 1\n",
        "        d1 = array_diff(Inew-Ia)\n",
        "        if(it>100):\n",
        "            break\n",
        "    if (d1 > d2):\n",
        "        print(ii)\n",
        "        ii = ii + 1\n",
        "        Inew = Ii\n",
        "    return Inew"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWikjcASWSPx"
      },
      "source": [
        "def iteration(itr, source, target, n, theta, j, dmin):\n",
        "    targett = target\n",
        "    sourcee = source\n",
        "    for i in range(itr):\n",
        "        #print (i)\n",
        "        adversarial_image = boundary_estimation(sourcee, targett, dmin)\n",
        "        adversarial_image = go_out(sourcee,adversarial_image,0.01)\n",
        "        (g, Iii2) = gradient_estimation(sourcee, targett, targett, n, theta)\n",
        "        targett = efficient_update(sourcee, targett, adversarial_image, Iii2, g, j)\n",
        "        if (pred(targett) == pred(source)):\n",
        "            j = j/2.0\n",
        "        fin = targett\n",
        "        if(pred(targett)==pred(sourcee)):\n",
        "            fin = go_out(sourcee,targett,0.01)\n",
        "        if(array_diff(fin-sourcee)<array_diff(adversarial_image-sourcee)):\n",
        "            targett = fin\n",
        "            #print(\"uopp\")\n",
        "\n",
        "    return fin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwrRNh52WSP3"
      },
      "source": [
        "final = iteration(300,source_image,target_image,5,0.196,5.0,1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol6vg2NxWSP-"
      },
      "source": [
        "source_image_path = 'gtsrb_dataset/kushbhinaamdede/0.png';\n",
        "img = (np.asarray(Image.open(source_image_path)))\n",
        "img1 = preprocess(img)\n",
        "source = np.array(img1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5lZUEfEWSQD",
        "outputId": "8bfbfe50-694f-48d1-98be-f671150285bf"
      },
      "source": [
        "arr = []\n",
        "for i in range(1,43):\n",
        "    print(i)\n",
        "    target_image_pathh = 'gtsrb_dataset/kushbhinaamdede/{0}.png'.format(i)\n",
        "    img = (np.asarray(Image.open(target_image_pathh)))\n",
        "    img1 = preprocess(img)\n",
        "    target = np.array(img1)\n",
        "    f = iteration(100,source,target,5,0.196,5.0,1.0)\n",
        "    arr.append(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/sakshi/dlProject/dlproject/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in ubyte_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrgD7UK5WSQK",
        "outputId": "25bbfb68-1ee5-4d4f-e225-e5536d26f88a"
      },
      "source": [
        "for i in range(42):\n",
        "    print(pred(arr[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n",
            "38\n",
            "1\n",
            "1\n",
            "38\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "38\n",
            "1\n",
            "1\n",
            "1\n",
            "38\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "8\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh1WPLJAWSQT"
      },
      "source": [
        "Image.fromarray(source.astype('uint8')).save('oo.png')\n",
        "Image.fromarray(arr[2].astype('uint8')).save('o0.png')\n",
        "# s = measure.compare_ssim(arr[1],arr[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlzn0ceQWSQY"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evqd3e6MWSQe"
      },
      "source": [
        "original = cv2.imread(\"oo.png\")\n",
        "perturb = cv2.imread(\"o0.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqgtI9N5WSQj",
        "outputId": "2ceae86e-97af-4546-e59f-6d60c312a29a"
      },
      "source": [
        "s = measure.compare_ssim(original,perturb,multichannel=True)\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8491636064596036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/sakshi/dlProject/dlproject/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20ff0exAWSQp",
        "outputId": "d0de9413-7fd4-43d7-d2a8-b792917574ae"
      },
      "source": [
        "original = cv2.imread(\"oo.png\")\n",
        "for i in range(42):\n",
        "    Image.fromarray(arr[i].astype('uint8')).save('o0.png')\n",
        "    perturb = cv2.imread('o0.png')\n",
        "    print(i,measure.compare_ssim(original,perturb,multichannel=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/sakshi/dlProject/dlproject/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.8638563696563702\n",
            "1 0.8601731118867479\n",
            "2 0.8491636064596036\n",
            "3 0.5853071229217088\n",
            "4 0.8793623636836144\n",
            "5 0.725452119893038\n",
            "6 0.7283911101181001\n",
            "7 0.9110326737243134\n",
            "8 0.846473262054997\n",
            "9 0.898105590816233\n",
            "10 0.7961759586655234\n",
            "11 0.9037002428630313\n",
            "12 0.4795590111181247\n",
            "13 0.760121866147534\n",
            "14 0.8513259876754575\n",
            "15 0.911840161397691\n",
            "16 0.7522741153556675\n",
            "17 0.4316132464752868\n",
            "18 0.7929031042224631\n",
            "19 0.8122035694103497\n",
            "20 0.8118060371115196\n",
            "21 0.9376700961116479\n",
            "22 0.48645602322363724\n",
            "23 0.8156317982715976\n",
            "24 0.4805004945690447\n",
            "25 0.6643707643514745\n",
            "26 0.6109604088463204\n",
            "27 0.8220965324392212\n",
            "28 0.808692374440188\n",
            "29 0.7847599129101823\n",
            "30 0.757587302481754\n",
            "31 0.8200416075965494\n",
            "32 0.8095893454733645\n",
            "33 0.5888707728214264\n",
            "34 0.5362472929834784\n",
            "35 0.5623844175021794\n",
            "36 0.8430409978867802\n",
            "37 0.7293989226620735\n",
            "38 0.4986993124303565\n",
            "39 0.8271368793706709\n",
            "40 0.8510807724897442\n",
            "41 0.8131894513250736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ibOpDpmWSQv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}